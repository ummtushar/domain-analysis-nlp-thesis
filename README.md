# Domain Analysis of Jupyter Notebooks using NLP

This project analyzes Jupyter Notebooks to classify them into specific domains using Natural Language Processing techniques. It extracts salient terms from notebook content (code, comments, markdown) and uses various embedding methods to classify notebooks into relevant domains.

## Project Overview

The pipeline consists of several stages:
1. **Data Mining**: Extract content from Jupyter notebooks
2. **Salient Term Extraction**: Use LDA, TF-IDF, and BOW methods  
3. **Embedding Generation**: Create embeddings using BERT, Word2Vec, and GloVe
4. **Domain Classification**: Classify notebooks using cosine similarity
5. **Evaluation**: Both quantitative (Precision@K) and qualitative (LLM-based) analysis
6. **Code Complexity Analysis**: Extract structural metrics and perform regression analysis

## AI Usage
The doctstrings and some in-line comments were generated by AI for enhanced readability. No novel code was generated by AI, it was purely used to structure, indent and improve readability. The necessary code was taken from respective documentations of the libraries used in this repository.

## Prerequisites

### Python Environment
- Python 3.7+
- Recommended: Create a virtual environment

### Required Libraries

```bash
# Core dependencies
pip install pandas numpy scipy matplotlib seaborn
pip install scikit-learn statsmodels

# NLP libraries  
pip install gensim nltk transformers torch
pip install spacy

# Jupyter notebook processing
pip install nbformat

# API clients for LLM evaluation
pip install groq 

# Additional utilities
pip install tqdm pathlib python-dotenv
```

### Environment Setup

1. Create a `.env` file in the project root with your API keys:
```
GROQ_API_KEY=your_groq_api_key_here
```

2. Download required NLTK data:
```python
import nltk
nltk.download('wordnet')
nltk.download('omw-1.4')
```

## Data Structure

Ensure your data is organized as follows:
```
project_root/
├── data/
│   ├── username1/
│   │   ├── notebook1/
│   │   │   ├── notebook1.ipynb
│   │   │   └── kernel-metadata.json
│   │   └── notebook2/
│   └── username2/
└── scripts/
```

## Execution Pipeline

### Step 1: Extract Notebook Content
```bash
python mine.py
```
This extracts code, comments, and markdown content from all notebooks in the `data/` directory and saves them to `nb_contents/`.

### Step 2: Extract Salient Terms  
```bash
python salient_terms.py
```
Processes the extracted content using LDA, TF-IDF, and BOW methods to identify salient terms. Results saved to `salient_terms/`.

### Step 3: Extract Kaggle Tags 
```bash
python mine_tags.py
```
Extracts domain tags from Kaggle notebook metadata for ground truth evaluation.

### Step 4: Generate Embeddings
```bash
python embeddings.py
```
Creates embeddings for salient terms using BERT, Word2Vec, and GloVe models. This step may take significant time as it downloads pre-trained models.

**Note**: This step requires substantial computational resources and internet connectivity for model downloads from Hugging Face.

### Step 5: Domain Classification (RQ1)
```bash
python domain_classification.py
```
Classifies notebooks into domains using cosine similarity between salient term embeddings and predefined domain embeddings. Outputs `domain_classification_results.csv`.

### Step 6: Quantitative Evaluation (RQ1)
```bash
python rq1_quantitative.py
```
Evaluates classification performance using Precision@K metrics. Requires ground truth tags from Step 3.

### Step 7: Code Complexity Analysis (RQ2)
```bash
python algo.py
```
Extracts code complexity metrics (lines of code, library usage, tensor operations, etc.) and creates `code_complexity.csv`.

### Step 8: Multinomial Regression (RQ2)
```bash
python multinomial_regression.py
```
Performs statistical analysis to correlate code complexity features with domain classifications.

### Step 9: Qualitative Evaluation (RQ1) (Optional)
Use rq1_qualitative.py for running without multi-threading. Use rq1_qualitative1.py for running with multi-threading.

```bash
# Using Groq/NVIDIA API
python rq1_qualitative.py

```
Uses LLMs to qualitatively assess the relevance and specificity of predicted domains.

## Key Output Files

- `nb_contents/` - Extracted notebook content
- `salient_terms/` - Salient terms for each notebook variation
- `*_embeddings/` - BERT, Word2Vec, and GloVe embeddings
- `domain_classification_results.csv` - Domain predictions for all combinations
- `precision_at_k_results.csv` - Quantitative evaluation results
- `code_complexity.csv` - Code complexity metrics
- `coefficients_with_significance.txt` - Regression analysis results
- `qualitative.csv` - LLM-based qualitative evaluation

## Configuration Options

### Salient Terms Extraction
- Modify topic numbers, passes, and other LDA parameters in `salient_terms.py`
- Adjust TF-IDF parameters (max_features, max_df, min_df)

### Embeddings  
- Change embedding models by modifying model names in `embeddings.py`
- Adjust special terms list for domain classification

### Domain Classification
- Modify similarity thresholds and top-k values in `domain_classification.py`

## Troubleshooting

### Common Issues

1. **Memory Issues**: The embedding generation step is memory-intensive. Consider processing smaller batches or using a machine with more RAM.

2. **API Rate Limits**: The qualitative evaluation scripts include rate limiting. 

3. **Missing Dependencies**: Some tensor operations require specific versions. If AST parsing fails, check Python version compatibility.

4. **Large Dataset Processing**: For very large datasets, consider implementing batch processing or using distributed computing.

### Performance Optimization

- Use GPU for BERT embeddings if available
- Implement caching for repeated API calls
- Consider using smaller embedding models for faster processing

## Hardware Requirements

- **Minimum**: 8GB RAM, modern CPU
- **Recommended**: 16GB+ RAM, GPU for embeddings, SSD storage
- **Network**: Stable internet connection for model downloads and API calls

## Citation

If you use this code, please cite the associated thesis:
```
@misc{gupta2025domain_code,
  title={Domain Analysis of Jupyter Notebooks using NLP - Implementation},
  author={Gupta, Tushar},
  year={2025},
  howpublished={\url{https://github.com/ummtushar/domain-analysis-nlp}},
  note={Python implementation of domain classification pipeline for Jupyter notebooks using NLP techniques including LDA, BERT, Word2Vec, and GloVe embeddings}
}
```

